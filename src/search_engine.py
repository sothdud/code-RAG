"""
Memgraph ê¸°ë°˜ì˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„
Vector(ì˜ë¯¸ ê²€ìƒ‰) + BM25(í‚¤ì›Œë“œ ê²€ìƒ‰) + Graph(ë§¥ë½/íë¦„ ê²€ìƒ‰)
ğŸ†• C# + XAML ì§€ì› ì¶”ê°€
"""
import re
from rank_bm25 import BM25Okapi
from qdrant_client.models import Filter, FieldCondition, MatchText, MatchAny
from .database import VectorStore
from .graph_store import GraphStore
from loguru import logger

class SmartSearchEngine:

    def __init__(self, vector_store: VectorStore, graph_store: GraphStore):
        self.db = vector_store
        self.graph = graph_store
        
        # BM25 ì¸ë±ìŠ¤ ì´ˆê¸°í™”
        logger.info("â³ Initializing BM25 Index from Vector Store...")
        
        self.all_chunks = self._fetch_all_docs_from_db()
        
        if self.all_chunks:
            tokenized_corpus = [self._tokenize_code(doc.get('content', '')) for doc in self.all_chunks]
            self.bm25 = BM25Okapi(tokenized_corpus)
            logger.success(f"âœ… BM25 Index Ready! (Loaded {len(self.all_chunks)} chunks)")
        else:
            logger.warning("âš ï¸ No data found in Qdrant. BM25 will be disabled until data is ingested.")
            self.bm25 = None

    def _tokenize_code(self, text: str):
        """
        ì½”ë“œìš© í† í¬ë‚˜ì´ì €: snake_case, CamelCase, íŠ¹ìˆ˜ë¬¸ì ë“±ì„ ë¶„ë¦¬
        """
        clean_text = re.sub(r"[_\.\(\)\[\]\{\}\=\:\,\;\"\'\/]", " ", text)
        return clean_text.lower().split()

    def _fetch_all_docs_from_db(self):
        """Qdrantì—ì„œ ëª¨ë“  ì²­í¬ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            all_points = []
            offset = None
            while True:
                points, offset = self.db.client.scroll(
                    collection_name=self.db.collection,
                    limit=100,
                    offset=offset,
                    with_payload=True,
                    with_vectors=False
                )
                for p in points:
                    if p.payload:
                        all_points.append(p.payload)
                
                if offset is None:
                    break
            return all_points
        except Exception as e:
            logger.error(f"âš ï¸ Failed to fetch docs for BM25: {e}")
            return []

    def reciprocal_rank_fusion(self, vector_results, bm25_results, k=60):
        """RRF ì•Œê³ ë¦¬ì¦˜: ë‘ ê²€ìƒ‰ ê²°ê³¼ì˜ ìˆœìœ„ë¥¼ í•©ì‚°í•˜ì—¬ ì¬ì •ë ¬"""
        fusion_scores = {}

        # Vector ê²°ê³¼ ì ìˆ˜ ë§¤ê¸°ê¸°
        for rank, item in enumerate(vector_results):
            payload = item.payload if hasattr(item, 'payload') else item
            doc_id = payload.get('qualified_name') or payload.get('filepath')
            
            if not doc_id: continue

            if doc_id not in fusion_scores:
                fusion_scores[doc_id] = {'doc': payload, 'score': 0}
            fusion_scores[doc_id]['score'] += 1 / (k + rank)

        # BM25 ê²°ê³¼ ì ìˆ˜ ë§¤ê¸°ê¸°
        for rank, item in enumerate(bm25_results):
            doc_id = item.get('qualified_name') or item.get('filepath')
            
            if not doc_id: continue

            if doc_id not in fusion_scores:
                fusion_scores[doc_id] = {'doc': item, 'score': 0}
            fusion_scores[doc_id]['score'] += 1 / (k + rank)

        # ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬
        sorted_results = sorted(fusion_scores.values(), key=lambda x: x['score'], reverse=True)
        
        return [item['doc'] for item in sorted_results]

    def _extract_filenames(self, query: str) -> list[str]:
        """
        ì§ˆë¬¸ì—ì„œ íŒŒì¼ëª…ë“¤ì„ ì¶”ì¶œ (Python + C# + XAML)
        """
        # Python íŒŒì¼
        py_files = re.findall(r'\b[\w-]+\.py\b', query)
        # C# íŒŒì¼
        cs_files = re.findall(r'\b[\w-]+\.cs\b', query)
        # XAML íŒŒì¼
        xaml_files = re.findall(r'\b[\w-]+\.xaml\b', query)
        
        return py_files + cs_files + xaml_files
    
    def _extract_function_names(self, query: str) -> list[str]:
        """
        ì§ˆë¬¸ì—ì„œ í•¨ìˆ˜ëª…/í´ë˜ìŠ¤ëª…/ì†ì„±ëª…ì„ ì¶”ì¶œ
        Python: snake_case
        C#: PascalCase, camelCase
        """
        # ì˜ë¬¸ì + ìˆ«ì + ì–¸ë”ìŠ¤ì½”ì–´ ì¡°í•©
        pattern = r'\b([A-Z][a-zA-Z0-9_]*|[a-z_][a-z0-9_]{2,})\b'
        candidates = re.findall(pattern, query)
        
        # ì¼ë°˜ ì˜ë‹¨ì–´ ì œì™¸
        common_words = {
            'what', 'does', 'how', 'why', 'where', 'when', 
            'function', 'class', 'method', 'file', 'code', 'this',
            'that', 'the', 'is', 'are', 'do', 'can', 'will', 'from',
            'property', 'event', 'handler', 'view', 'model', 'ViewModel',
            'get', 'set', 'public', 'private', 'void', 'string', 'int'
        }
        
        function_names = []
        for c in candidates:
            # ìµœì†Œ 3ì ì´ìƒì´ê±°ë‚˜ ì–¸ë”ìŠ¤ì½”ì–´/ëŒ€ë¬¸ì í¬í•¨
            if (len(c) >= 3 or '_' in c or c[0].isupper()) and c.lower() not in common_words:
                function_names.append(c)
        
        return list(set(function_names))  # ì¤‘ë³µ ì œê±°
    
    def _get_exact_function_chunks(self, function_names: list[str]) -> list:
        """í•¨ìˆ˜ëª…ê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ì²­í¬ë“¤ì„ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°"""
        if not function_names or not self.all_chunks:
            return []
        
        exact_matches = []
        seen_qns = set()
        
        for chunk in self.all_chunks:
            chunk_name = chunk.get('name', '')
            qn = chunk.get('qualified_name', '')
            
            if qn in seen_qns:
                continue
            
            # í•¨ìˆ˜ëª…ì´ ì •í™•íˆ ì¼ì¹˜í•˜ê±°ë‚˜ qualified_name ëë¶€ë¶„ì´ ì¼ì¹˜
            for target_name in function_names:
                if chunk_name == target_name or qn.endswith(f'.{target_name}'):
                    exact_matches.append(chunk)
                    seen_qns.add(qn)
                    logger.info(f"  âœ… Exact match found: {qn}")
                    break
        
        return exact_matches

    def search(self, query: str, top_k: int = 5):
        """
        [í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸]
        1. Exact Function Name Matching
        2. Keyword Search (BM25)
        3. Vector Search (Dense)
        4. RRF Fusion
        5. Reranking
        6. Context Expansion (Graph)
        """
        print(f"ğŸ” Hybrid Searching for: '{query}'")

        # 0. í•¨ìˆ˜ëª… ì •í™• ë§¤ì¹­
        target_functions = self._extract_function_names(query)
        exact_function_chunks = []
        
        if target_functions:
            print(f"  ğŸ¯ Detected names: {target_functions}")
            exact_function_chunks = self._get_exact_function_chunks(target_functions)
            print(f"  âœ… Found {len(exact_function_chunks)} exact matches")
        
        # 1. íŒŒì¼ëª… í•„í„° í™•ì¸
        target_files = self._extract_filenames(query)
        search_filters = None
        if target_files:
            print(f"  ğŸ“‚ Filter by files: {target_files}")
            search_filters = Filter(
                should=[
                    FieldCondition(
                        key="filepath", 
                        match=MatchText(text=fname)
                    ) for fname in target_files
                ]
            )

        # 2. Vector Search
        vector_candidates = self.db.search(query, top_k=top_k * 4, query_filter=search_filters)
        
        # 3. Keyword Search (BM25)
        bm25_candidates = []
        if self.bm25:
            tokenized_query = self._tokenize_code(query)
            bm25_candidates = self.bm25.get_top_n(tokenized_query, self.all_chunks, n=top_k * 4)

        # 4. RRF Fusion
        print(f"  ğŸ§¬ Fusing: Vector({len(vector_candidates)}) + BM25({len(bm25_candidates)})")
        
        candidates_before_rerank = self.reciprocal_rank_fusion(
            vector_candidates, 
            bm25_candidates, 
            k=60
        )

        # 4.5 ì •í™• ë§¤ì¹­ì„ ìµœìƒìœ„ì— ì‚½ì…
        if exact_function_chunks:
            exact_qns = {c.get('qualified_name') for c in exact_function_chunks}
            candidates_before_rerank = [
                c for c in candidates_before_rerank 
                if c.get('qualified_name') not in exact_qns
            ]
            candidates_before_rerank = exact_function_chunks + candidates_before_rerank
            print(f"  ğŸ¯ Exact matches promoted to top!")

        # 5. Reranking
        slice_for_rerank = candidates_before_rerank[:20]
        
        if slice_for_rerank:
            print(f"  âš–ï¸ Reranking top {len(slice_for_rerank)} candidates...")
            
            if exact_function_chunks:
                non_exact = [c for c in slice_for_rerank if c not in exact_function_chunks]
                reranked_rest = self.db.rerank(query, non_exact, top_k=max(1, top_k - len(exact_function_chunks)))
                final_results = exact_function_chunks + reranked_rest
                final_results = final_results[:top_k]
            else:
                final_results = self.db.rerank(query, slice_for_rerank, top_k=top_k)
        else:
            final_results = []

        if not final_results:
            print("  âš ï¸ No candidates found.")
            return []

        # 6. Graph Context Expansion
        enhanced_results = []

        for i, payload in enumerate(final_results):
            qualified_name = payload.get('qualified_name')

            context_entry = {
                "chunk": payload,
                "flow_context": [],
                "related_code": [],
            }

            if qualified_name:
                # ì‹¤í–‰ íë¦„ ê°€ì ¸ì˜¤ê¸°
                context_entry["flow_context"] = self.graph.get_execution_flow(qualified_name, depth=2)

                # ìƒìœ„ 3ê°œë§Œ Callee ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
                if i < 3:
                    callees = self.graph.get_callees(qualified_name)
                    if callees:
                        context_entry['related_code'] = self.db.retrieve_by_filenames(callees)

            enhanced_results.append(context_entry)

        return enhanced_results
    
    def search_by_language(self, query: str, language: str, top_k: int = 10):
        """
        ğŸ†• ì–¸ì–´ë³„ ê²€ìƒ‰ (python, c_sharp, xaml)
        """
        print(f"ğŸ” Searching {language.upper()} code for: '{query}'")
        
        language_filter = Filter(
            must=[
                FieldCondition(
                    key="language",
                    match=MatchText(text=language)
                )
            ]
        )
        
        results = self.db.search(query, top_k=top_k, query_filter=language_filter)
        
        # Payload ì¶”ì¶œ
        payloads = [
            r.payload if hasattr(r, 'payload') else r 
            for r in results
        ]
        
        return [{
            "chunk": p,
            "flow_context": [],
            "related_code": []
        } for p in payloads]