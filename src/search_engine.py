"""
Memgraph ê¸°ë°˜ì˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„
Vector(ì˜ë¯¸ ê²€ìƒ‰) + BM25(í‚¤ì›Œë“œ ê²€ìƒ‰) + Graph(ë§¥ë½/íë¦„ ê²€ìƒ‰)
"""
import re
from rank_bm25 import BM25Okapi
from qdrant_client.models import Filter, FieldCondition, MatchText
from .database import VectorStore
from .graph_store import GraphStore
from loguru import logger

class SmartSearchEngine:

    def __init__(self, vector_store: VectorStore, graph_store: GraphStore):
        self.db = vector_store
        self.graph = graph_store
        
        # ---------------------------------------------------------
        # ğŸš€ [NEW] BM25 ì¸ë±ìŠ¤ ì´ˆê¸°í™” (ë©”ëª¨ë¦¬ ë¡œë“œ)
        # ---------------------------------------------------------
        # ì„œë²„ ì‹œì‘ ì‹œ Qdrantì— ìˆëŠ” ëª¨ë“  ì½”ë“œë¥¼ ê°€ì ¸ì™€ì„œ BM25 ì¸ë±ìŠ¤ë¥¼ ë§Œë“­ë‹ˆë‹¤.
        # (ì½”ë“œ RAG íŠ¹ì„±ìƒ 'ì •í™•í•œ ë³€ìˆ˜ëª…/í•¨ìˆ˜ëª…' ë§¤ì¹­ì„ ìœ„í•´ í•„ìˆ˜ì…ë‹ˆë‹¤.)
        logger.info("â³ Initializing BM25 Index from Vector Store...")
        
        self.all_chunks = self._fetch_all_docs_from_db()
        
        if self.all_chunks:
            # ì½”ë“œ íŠ¹í™” í† í¬ë‚˜ì´ì§• ì ìš©
            tokenized_corpus = [self._tokenize_code(doc.get('content', '')) for doc in self.all_chunks]
            self.bm25 = BM25Okapi(tokenized_corpus)
            logger.success(f"âœ… BM25 Index Ready! (Loaded {len(self.all_chunks)} chunks)")
        else:
            logger.warning("âš ï¸ No data found in Qdrant. BM25 will be disabled until data is ingested.")
            self.bm25 = None

    def _tokenize_code(self, text: str):
        """
        ì½”ë“œìš© í† í¬ë‚˜ì´ì €: snake_case, CamelCase, íŠ¹ìˆ˜ë¬¸ì ë“±ì„ ë¶„ë¦¬í•˜ì—¬ ì¸ë±ì‹±
        ì˜ˆ: "INVALID_KEY" -> ["invalid", "key"]
        """
        # íŠ¹ìˆ˜ë¬¸ìë¥¼ ê³µë°±ìœ¼ë¡œ ì¹˜í™˜
        clean_text = re.sub(r"[_\.\(\)\[\]\{\}\=\:\,\;\"\'\/]", " ", text)
        return clean_text.lower().split()

    def _fetch_all_docs_from_db(self):
        """Qdrantì—ì„œ ëª¨ë“  ì²­í¬ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            all_points = []
            offset = None
            # Qdrant scroll ê¸°ëŠ¥ìœ¼ë¡œ ì „ì²´ ë°ì´í„° ìˆœíšŒ
            while True:
                points, offset = self.db.client.scroll(
                    collection_name=self.db.collection,
                    limit=100,
                    offset=offset,
                    with_payload=True,
                    with_vectors=False
                )
                # payload(ë©”íƒ€ë°ì´í„°+content)ë§Œ ì €ì¥
                for p in points:
                    if p.payload:
                        all_points.append(p.payload)
                
                if offset is None:
                    break
            return all_points
        except Exception as e:
            logger.error(f"âš ï¸ Failed to fetch docs for BM25: {e}")
            return []

    def reciprocal_rank_fusion(self, vector_results, bm25_results, k=60):
        """
        ğŸ§¬ RRF ì•Œê³ ë¦¬ì¦˜: ë‘ ê²€ìƒ‰ ê²°ê³¼ì˜ ìˆœìœ„ë¥¼ í•©ì‚°í•˜ì—¬ ì¬ì •ë ¬
        Score = 1 / (k + rank)
        """
        fusion_scores = {}

        # 1. Vector ê²°ê³¼ ì ìˆ˜ ë§¤ê¸°ê¸°
        for rank, item in enumerate(vector_results):
            # Qdrant ê²°ê³¼ëŠ” ê°ì²´ì´ë¯€ë¡œ payload ì ‘ê·¼
            payload = item.payload if hasattr(item, 'payload') else item
            doc_id = payload.get('qualified_name') or payload.get('filepath') # ê³ ìœ  í‚¤
            
            if not doc_id: continue

            if doc_id not in fusion_scores:
                fusion_scores[doc_id] = {'doc': payload, 'score': 0}
            fusion_scores[doc_id]['score'] += 1 / (k + rank)

        # 2. BM25 ê²°ê³¼ ì ìˆ˜ ë§¤ê¸°ê¸°
        for rank, item in enumerate(bm25_results):
            # BM25 ê²°ê³¼ëŠ” ë”•ì…”ë„ˆë¦¬(payload) ê·¸ ìì²´
            doc_id = item.get('qualified_name') or item.get('filepath')
            
            if not doc_id: continue

            if doc_id not in fusion_scores:
                fusion_scores[doc_id] = {'doc': item, 'score': 0}
            fusion_scores[doc_id]['score'] += 1 / (k + rank)

        # 3. ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬
        sorted_results = sorted(fusion_scores.values(), key=lambda x: x['score'], reverse=True)
        
        # ë¬¸ì„œ ê°ì²´ë§Œ ë°˜í™˜
        return [item['doc'] for item in sorted_results]

    def _extract_filenames(self, query: str) -> list[str]:
        """ì§ˆë¬¸ì—ì„œ .py íŒŒì¼ëª…ë“¤ì„ ì¶”ì¶œ"""
        return re.findall(r'\b[\w-]+\.py\b', query)

    def search(self, query: str, top_k: int = 5):
        """
        [í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸]
        1. Keyword Search (BM25): ì •í™•í•œ ë‹¨ì–´ ë§¤ì¹­
        2. Vector Search (Dense): ì˜ë¯¸ì  ìœ ì‚¬ì„±
        3. RRF Fusion: ìˆœìœ„ í˜¼í•©
        4. Reranking (Cross-Encoder): [NEW!] ì •ë°€ ì¬ê²€ì¦
        5. Context Expansion: Graph DB ë¬¸ë§¥ ë³´ê°•
        """
        print(f"ğŸ” Hybrid Searching for: '{query}'")

        # 1. íŒŒì¼ëª… í•„í„° í™•ì¸ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        target_files = self._extract_filenames(query)
        search_filters = None
        if target_files:
            print(f"  ğŸ“‚ Filter by files: {target_files}")
            search_filters = Filter(
                should=[
                    FieldCondition(
                        key="filepath", 
                        match=MatchText(text=fname)
                    ) for fname in target_files
                ]
            )

        # ---------------------------------------------------------
        # 2. Vector Search (Dense)
        # ---------------------------------------------------------
        # RRFë¥¼ ìœ„í•´ ë„‰ë„‰í•˜ê²Œ(4ë°°ìˆ˜) ê°€ì ¸ì˜µë‹ˆë‹¤.
        vector_candidates = self.db.search(query, top_k=top_k * 4, query_filter=search_filters)
        
        # ---------------------------------------------------------
        # 3. Keyword Search (BM25)
        # ---------------------------------------------------------
        bm25_candidates = []
        if self.bm25:
            tokenized_query = self._tokenize_code(query)
            bm25_candidates = self.bm25.get_top_n(tokenized_query, self.all_chunks, n=top_k * 4)

        # ---------------------------------------------------------
        # 4. RRF (Reciprocal Rank Fusion) ê²°í•©
        # ---------------------------------------------------------
        print(f"  ğŸ§¬ Fusing: Vector({len(vector_candidates)}) + BM25({len(bm25_candidates)})")
        
        # ì—¬ê¸°ì„œ ë‚˜ì˜¨ í›„ë³´êµ°ì€ ì•½ 20~40ê°œ ì •ë„ì…ë‹ˆë‹¤.
        candidates_before_rerank = self.reciprocal_rank_fusion(
            vector_candidates, 
            bm25_candidates, 
            k=60
        )

        # ---------------------------------------------------------
        # ğŸ”¥ [4.5] Reranking (Cross-Encoder) ì¶”ê°€ëœ ë¶€ë¶„
        # ---------------------------------------------------------
        # RRF ê²°ê³¼ ì¤‘ ìƒìœ„ 20ê°œë§Œ ì¶”ë ¤ì„œ ë¦¬ë­ì»¤ì—ê²Œ ê²€ì‚¬ ë§¡ê¹ë‹ˆë‹¤.
        slice_for_rerank = candidates_before_rerank[:20]
        
        if slice_for_rerank:
            print(f"  âš–ï¸ Reranking top {len(slice_for_rerank)} candidates...")
            
            # database.pyì˜ rerank ë©”ì„œë“œê°€ (query, results, top_k)ë¥¼ ë°›ì•„ 
            # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìµœì¢… top_kê°œë§Œ ëŒë ¤ì¤ë‹ˆë‹¤.
            final_results = self.db.rerank(query, slice_for_rerank, top_k=top_k)
        else:
            final_results = []

        if not final_results:
            print("  âš ï¸ No candidates found.")
            return []

        # ---------------------------------------------------------
        # 5. Graph Context Expansion (ê¸°ì¡´ ë³€ìˆ˜ëª… ìœ ì§€)
        # ---------------------------------------------------------
        enhanced_results = []

        for i, payload in enumerate(final_results):
            # payloadëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœ
            qualified_name = payload.get('qualified_name')

            context_entry = {
                "chunk": payload,
                "flow_context": [],
                "related_code": [],
            }

            if qualified_name:
                # 1. ì‹¤í–‰ íë¦„ ê°€ì ¸ì˜¤ê¸° (Graph)
                # ë¦¬ë­í‚¹ìœ¼ë¡œ ìˆœìœ„ê°€ ë°”ë€Œì—ˆìœ¼ë¯€ë¡œ, ì´ì œ ì§„ì§œ ì¤‘ìš”í•œ ìƒìœ„ê¶Œ ë…€ì„ë“¤ë§Œ Graphë¥¼ íƒ‘ë‹ˆë‹¤.
                context_entry["flow_context"] = self.graph.get_execution_flow(qualified_name, depth=2)

                # 2. ìƒìœ„ 3ê°œë§Œ Callee(í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜) ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
                if i < 3:
                    callees = self.graph.get_callees(qualified_name)
                    if callees:
                        context_entry['related_code'] = self.db.retrieve_by_filenames(callees)

            enhanced_results.append(context_entry)

        return enhanced_results