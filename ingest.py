import os
import sys
import json
import hashlib
from pathlib import Path
from dotenv import load_dotenv
from rich.console import Console
from rich.progress import track

# Qdrant Filter ê´€ë ¨ ì„í¬íŠ¸ (ì‚­ì œìš©)
from qdrant_client.models import Filter, FieldCondition, MatchText

from src.parser import ASTParser
from src.graph_builder import GraphBuilder
from src.database import VectorStore
from src.graph_store import GraphStore
from src.path_utils import should_skip_path

load_dotenv()
console = Console()

STATE_FILE = ".ingest_state.json"

def calculate_file_hash(filepath: Path) -> str:
    """íŒŒì¼ ë‚´ìš©ì˜ MD5 í•´ì‹œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    hash_md5 = hashlib.md5()
    try:
        with open(filepath, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    except FileNotFoundError:
        return ""

def load_state() -> dict:
    """ì´ì „ ì¸ë±ì‹± ìƒíƒœë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    if os.path.exists(STATE_FILE):
        try:
            with open(STATE_FILE, "r") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}

def save_state(state: dict):
    """í˜„ì¬ ì¸ë±ì‹± ìƒíƒœë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    with open(STATE_FILE, "w") as f:
        json.dump(state, f, indent=2)

def main():
    # ============================================
    # ì˜µì…˜ íŒŒì‹±
    # ============================================
    FULL_RESET = "--full" in sys.argv or "--reset" in sys.argv
    
    if FULL_RESET:
        console.print("\n[bold red]ğŸ”„ FULL RESET MODE ENABLED[/bold red]")
        console.print("  â†’ Will recreate entire database\n")
    
    # 1. ì„¤ì •
    TARGET_DIR = Path(os.getenv("SOURCE_CODE_PATH", "./data"))
    if not TARGET_DIR.exists():
        console.print(f"[red]âŒ ê²½ë¡œ ì—†ìŒ: {TARGET_DIR}[/red]")
        return

    parser = ASTParser()
    graph_builder = GraphBuilder()
    db = VectorStore()
    graph_store = GraphStore()
    
    # ============================================
    # FULL RESET: ì „ì²´ DB ì´ˆê¸°í™”
    # ============================================
    if FULL_RESET:
        console.print("[bold yellow]ğŸ—‘ï¸ Dropping existing collections...[/bold yellow]")
        db.recreate_collection()
        graph_store.clear_all_data()
        
        # ìƒíƒœ íŒŒì¼ë„ ì‚­ì œ
        if os.path.exists(STATE_FILE):
            os.remove(STATE_FILE)
        
        console.print("[green]âœ“ Database reset complete[/green]\n")
        previous_state = {}
    else:
        previous_state = load_state()
    
    # 2. ìƒíƒœ ë¡œë“œ ë° ë³€ê²½ ê°ì§€
    console.print(f"[bold yellow]ğŸ” Phase 1: Detecting Changes...[/bold yellow]")
    
    current_state = {}
    
    all_files = []
    # íŒŒì¼ íƒìƒ‰
    for root, dirs, files in os.walk(TARGET_DIR):
        root_path = Path(root)
        
        # ë””ë ‰í† ë¦¬ ì œì™¸ ì²˜ë¦¬ (ì¬ê·€ì  íƒìƒ‰ íš¨ìœ¨í™”)
        dirs[:] = [d for d in dirs if not should_skip_path(root_path / d, TARGET_DIR)]
        
        for file in files:
            if not file.endswith('.py'): continue
            file_path = root_path / file
            if should_skip_path(file_path, TARGET_DIR): continue
            
            all_files.append(file_path)

    # ë³€ê²½ ì‚¬í•­ ë¶„ë¥˜
    files_to_embed = []      # ì„ë² ë”© ìƒˆë¡œ í•´ì•¼ í•  íŒŒì¼ (ì‹ ê·œ/ìˆ˜ì •)
    files_to_delete = []     # DBì—ì„œ ì§€ì›Œì•¼ í•  íŒŒì¼ (ìˆ˜ì •/ì‚­ì œ)
    unchanged_files = []     # ë³€ê²½ ì—†ëŠ” íŒŒì¼
    
    # 2-1. ì‹ ê·œ ë° ìˆ˜ì • íŒŒì¼ ê°ì§€
    for file_path in all_files:
        str_path = str(file_path)
        current_hash = calculate_file_hash(file_path)
        current_state[str_path] = current_hash
        
        prev_hash = previous_state.get(str_path)
        
        # FULL RESET ëª¨ë“œë©´ ëª¨ë“  íŒŒì¼ ì¬ì²˜ë¦¬
        if FULL_RESET:
            files_to_embed.append(file_path)
            console.print(f"  [cyan]â†’ Queue:[/cyan] {file_path.name}")
        elif prev_hash != current_hash:
            if prev_hash is None:
                console.print(f"  [green]+ New:[/green] {file_path.name}")
            else:
                console.print(f"  [yellow]* Modified:[/yellow] {file_path.name}")
                files_to_delete.append(str_path) # ìˆ˜ì •ëœ ê²½ìš° ê¸°ì¡´ ê±° ì‚­ì œ í•„ìš”
            files_to_embed.append(file_path)
        else:
            unchanged_files.append(file_path)

    # 2-2. ì‚­ì œëœ íŒŒì¼ ê°ì§€ (FULL RESET ëª¨ë“œì—ì„  ë¶ˆí•„ìš”)
    if not FULL_RESET:
        for old_path in previous_state:
            if old_path not in current_state:
                console.print(f"  [red]- Deleted:[/red] {old_path}")
                files_to_delete.append(old_path)

    # ë³€ê²½ì‚¬í•­ì´ ì—†ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ
    if not FULL_RESET and not files_to_embed and not files_to_delete:
        console.print("\n[bold green]âœ… No changes detected. System is up to date.[/bold green]")
        return

    # ---------------------------------------------------------
    # 3. ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬ (Incremental Only)
    # ---------------------------------------------------------
    if not FULL_RESET and files_to_delete:
        console.print(f"\n[bold red]ğŸ—‘ï¸ Removing obsolete chunks ({len(files_to_delete)} files)...[/bold red]")
        # Qdrantì—ì„œ íŒŒì¼ ê²½ë¡œ ê¸°ì¤€ìœ¼ë¡œ ì‚­ì œ
        for file_path in files_to_delete:
            try:
                db.client.delete(
                    collection_name=db.collection,
                    points_selector=Filter(
                        must=[
                            FieldCondition(
                                key="filepath",
                                match=MatchText(text=file_path)
                            )
                        ]
                    )
                )
            except Exception as e:
                console.print(f"  âš ï¸ Failed to delete {file_path}: {e}")

    # ---------------------------------------------------------
    # 4. íŒŒì‹± ë° ê·¸ë˜í”„ ë¹Œë“œ
    # ---------------------------------------------------------
    console.print(f"\n[bold cyan]ğŸ§  Phase 2: Parsing & Building Structure...[/bold cyan]")
    
    all_chunks_for_graph = []       # ê·¸ë˜í”„ìš© (ì „ì²´)
    chunks_to_upsert = []           # ë²¡í„° ì €ì¥ìš© (ë³€ê²½ë¶„ë§Œ)
    
    # FULL RESET: ëª¨ë“  íŒŒì¼ ì²˜ë¦¬
    # Incremental: ë³€ê²½ëœ íŒŒì¼ + ê·¸ë˜í”„ìš© ì „ì²´ íŒŒì¼
    files_to_parse = all_files if FULL_RESET else all_files
    
    for file_path in track(files_to_parse, description="Parsing AST..."):
        try:
            chunks = parser.parse_file(str(file_path))
            
            # ê·¸ë˜í”„ ë¹Œë”ì—” ë¬´ì¡°ê±´ ì¶”ê°€ (ì „ì²´ ë¬¸ë§¥ í˜•ì„±)
            for chunk in chunks:
                graph_builder.add_chunk(chunk)
                all_chunks_for_graph.append(chunk)
            
            # ë²¡í„° DBì—” ë³€ê²½ëœ íŒŒì¼ë§Œ ì¶”ê°€ (ë˜ëŠ” FULL RESET ì‹œ ì „ë¶€)
            if FULL_RESET or file_path in files_to_embed:
                chunks_to_upsert.extend(chunks)
                
        except Exception as e:
            console.print(f"  [red]Error parsing {file_path.name}: {e}[/red]")

    # ---------------------------------------------------------
    # 5. Vector DB ì €ì¥
    # ---------------------------------------------------------
    if chunks_to_upsert:
        console.print(f"\n[bold green]ğŸ’¾ Phase 3: Updating Vector DB ({len(chunks_to_upsert)} chunks)...[/bold green]")
        # â­ calls í•„í„°ë§ì€ ì´ë¯¸ parser.pyì™€ database.pyì—ì„œ ì²˜ë¦¬ë¨
        db.upsert_chunks(chunks_to_upsert)
    else:
        console.print("\n[dim]ğŸ’¾ Phase 3: Vector DB skipped (No new content)[/dim]")

    # ---------------------------------------------------------
    # 6. Graph DB ì €ì¥ (Full Sync)
    # ---------------------------------------------------------
    console.print(f"\n[bold magenta]ğŸ•¸ï¸ Phase 4: Syncing Graph DB...[/bold magenta]")
    
    call_graph = graph_builder.build_call_graph()
    
    # Memgraph ì´ˆê¸°í™” í›„ ì „ì²´ ë…¸ë“œ/ì—£ì§€ ë‹¤ì‹œ ì“°ê¸°
    if FULL_RESET:
        graph_store.clear_all_data()
    graph_store.save_graph_data(all_chunks_for_graph, call_graph.edges)

    # ---------------------------------------------------------
    # 7. ìƒíƒœ ì €ì¥
    # ---------------------------------------------------------
    save_state(current_state)
    
    if FULL_RESET:
        console.print("\n[bold blue]âœ¨ Full Reset Complete![/bold blue]")
    else:
        console.print("\n[bold blue]âœ¨ Incremental Ingest Complete![/bold blue]")
    
    console.print(f"  â€¢ Total files: {len(all_files)}")
    console.print(f"  â€¢ Processed: {len(files_to_embed)}")
    console.print(f"  â€¢ Unchanged: {len(unchanged_files)}")

if __name__ == "__main__":
    main()