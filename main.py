from rich.console import Console
from rich.panel import Panel
from rich.markdown import Markdown
from rich.table import Table
from rich import box
from rich.progress import Progress, SpinnerColumn, TextColumn
import re
import json

# ëª¨ë“ˆ ì„í¬íŠ¸ (ê²½ë¡œëŠ” í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ì¡°ì • í•„ìš”)
from src.database import VectorStore
from src.llm import LocalLLM
from src.graph_store import GraphStore
from src.search_engine import SmartSearchEngine
from src import prompts 

console = Console()


# ===================================================================
# ğŸ” Query Analysis (ì§ˆë¬¸ ìœ í˜• ìë™ ê°ì§€)
# ===================================================================

def detect_query_type(query: str, llm) -> dict:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë™ì ìœ¼ë¡œ íŒŒì•…í•©ë‹ˆë‹¤. (ê·œì¹™ ê¸°ë°˜ X -> AI ê¸°ë°˜ O)
    """
    
    # 2. ë¶„ë¥˜ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì‘ì„±
    router_prompt = """
    ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” 'Router' AIì…ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•´ì„œ ì•„ë˜ 4ê°€ì§€ ìœ í˜• ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ê³  ì¤‘ìš” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

    [ë¶„ë¥˜ ìœ í˜•]
    1. bug: ì—ëŸ¬ ìˆ˜ì •, ì˜¤ë¥˜ ì°¾ê¸°, ë””ë²„ê¹… ìš”ì²­ (ì˜ˆ: "ì´ê±° ì™œ ì•ˆë¼?", "Traceback ì—ëŸ¬")
    2. flow: ì½”ë“œì˜ ì‹¤í–‰ íë¦„, ë™ì‘ ì›ë¦¬, ìˆœì„œ ì„¤ëª… ìš”ì²­ (ì˜ˆ: "ì´ê²Œ ì–´ë–»ê²Œ ëŒì•„ê°€ëŠ”ê±°ì•¼?")
    3. search: íŠ¹ì • ê¸°ëŠ¥/íŒŒì¼ ì°¾ê¸°, ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ì˜ˆ: "ë¡œê·¸ì¸ ê¸°ëŠ¥ ì–´ë””ìˆì–´?", "User í´ë˜ìŠ¤ ì°¾ì•„ì¤˜")
    4. general: ê·¸ ì™¸ ì¼ë°˜ì ì¸ ì½”ë”© ì§ˆë¬¸

    [ì¶œë ¥ í˜•ì‹ (JSON)]
    {
        "type": "ìœ í˜•(bug, flow, search, general ì¤‘ íƒ1)",
        "filenames": ["ì–¸ê¸‰ëœ_íŒŒì¼ëª….py"],
        "target_name": "ì–¸ê¸‰ëœ_í•¨ìˆ˜_ë˜ëŠ”_í´ë˜ìŠ¤ëª…(ì—†ìœ¼ë©´ null)",
        "keywords": ["ê²€ìƒ‰ìš©_í•µì‹¬í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"]
    }
    
    ë°˜ë“œì‹œ JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì„¤ëª…ì€ í•„ìš” ì—†ìŠµë‹ˆë‹¤.
    """

    # 3. LLMì—ê²Œ íŒë‹¨ ìš”ì²­
    try:
        # LLMì—ê²Œ ë¬¼ì–´ë³´ê¸°
        response_text = llm.generate_response(router_prompt, query)
        
        # 4. JSON íŒŒì‹± (LLMì´ ê°€ë” ë§ˆí¬ë‹¤ìš´ ```json ... ``` ì„ ë¶™ì¼ ìˆ˜ ìˆì–´ì„œ ì œê±°)
        clean_json = response_text.replace("```json", "").replace("```", "").strip()
        result = json.loads(clean_json)
        
        # í•„ìˆ˜ í•„ë“œ ì•ˆì „ì¥ì¹˜ (í˜¹ì‹œ LLMì´ ë¹¼ë¨¹ì—ˆì„ ê²½ìš° ëŒ€ë¹„)
        if 'filenames' not in result: result['filenames'] = []
        if 'target_name' not in result: result['target_name'] = None
        
        # í˜¸í™˜ì„±ì„ ìœ„í•´ ê¸°ì¡´ ì½”ë“œì—ì„œ ì“°ë˜ í•„ë“œ ì¶”ê°€
        result['filename'] = result['filenames'][0] if result['filenames'] else None
        result['has_traceback'] = 'traceback' in query.lower() # ì´ê±´ í™•ì‹¤í•˜ë‹ˆê¹Œ ë£° ìœ ì§€í•´ë„ ë¨
        
        return result

    except Exception as e:
        # LLMì´ JSONì„ ì˜ëª» ì¤¬ê±°ë‚˜ ì—ëŸ¬ê°€ ë‚˜ë©´ ì•ˆì „í•˜ê²Œ ê¸°ë³¸ê°’ ë¦¬í„´
        console.print(f"[red]âš ï¸ ë¼ìš°íŒ… ì‹¤íŒ¨ (ê¸°ë³¸ê°’ ì‚¬ìš©): {e}[/red]")
        return {
            "type": "general",
            "filenames": [],
            "filename": None,
            "target_name": None,
            "has_traceback": False
        }
def build_optimized_prompt(query: str, results: list, query_info: dict) -> str:
    """
    ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
    """
    # Context ìƒì„±
    if results and isinstance(results[0], dict) and 'filepath' in results[0] and 'chunk' not in results[0]:
        context_str = prompts.build_file_context(results)
    else:
        context_str = prompts.build_smart_search_context(results)
    
    # ì§ˆë¬¸ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ ì„ íƒ
    qtype = query_info['type']
    
    if qtype == 'existence':
        return prompts.get_existence_check_prompt(
            query, context_str, query_info['target_name'] or "unknown"
        )
    elif qtype == 'flow':
        return prompts.get_flow_analysis_prompt(query, context_str)
    elif qtype == 'bug':
        return prompts.get_bug_analysis_prompt(query, context_str)
    elif qtype == 'file_summary':
        return prompts.get_file_summary_prompt(
            query, context_str, query_info['filename']
        )
    elif qtype == 'error':
        traceback_match = re.search(r'(Traceback.*?)(?:\n\n|\Z)', query, re.DOTALL)
        traceback = traceback_match.group(1) if traceback_match else query
        return prompts.get_error_diagnostic_prompt(query, context_str, traceback)
    else:
        return prompts.get_general_prompt(query, context_str)


# ===================================================================
# ğŸ“Š Evidence Panel (ê²€ìƒ‰ ê²°ê³¼ ì‹œê°í™”)
# ===================================================================

def print_evidence_panel(results: list, query_info: dict):
    table = Table(
        title=f"ğŸ” Analysis Context [{query_info['type'].upper()}]", 
        box=box.ROUNDED, 
        show_lines=True
    )

    table.add_column("File", style="cyan", no_wrap=True, width=30)
    table.add_column("Type", style="magenta", width=10)
    table.add_column("Function/Class", style="green", width=25)
    table.add_column("Line", justify="right", style="yellow", width=10)

    for item in results[:15]:  # ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ 15ê°œë¡œ ì œí•œ
        if isinstance(item, dict) and 'chunk' in item:
            chunk = item['chunk']
            table.add_row(
                chunk.get('filepath', 'Unknown')[-30:], 
                chunk.get('type', 'code'),
                chunk.get('name', 'Unknown'),
                str(chunk.get('start_line', '?'))
            )
        elif isinstance(item, dict) and 'filepath' in item:
            table.add_row(
                item['filepath'][-30:],
                item.get('type', 'file'),
                item.get('name', 'Entire File'),
                str(item.get('start_line', '-'))
            )

    console.print(table)
    console.print(f"[dim]Total: {len(results)} candidates[/dim]\n")


# ===================================================================
# ğŸ¯ Main Application
# ===================================================================

def main():
    console.print(Panel.fit(
        "[bold blue]ğŸ¤– Production-Ready Code RAG (AI Router)[/bold blue]\n"
    ))
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        transient=True,
    ) as progress:
        task = progress.add_task("[cyan]Initializing system...", total=None)
        
        db = VectorStore()
        llm = LocalLLM()
        graph_store = GraphStore()
        engine = SmartSearchEngine(db, graph_store)
        
        progress.update(task, completed=True)
    
    console.print("[green]âœ… System ready[/green]\n")


    try:
        while True:
            query = console.input("\n[bold green]ì§ˆë¬¸ (exit): [/bold green]")
            if query.lower() in ['exit', 'quit', 'q']:
                break

            # ===================================================================
            # Step 1: ì§ˆë¬¸ ìœ í˜• ìë™ ê°ì§€ (LLM ì‚¬ìš©)
            # ===================================================================
            with console.status("[bold blue]ğŸ¤” Intent Classification...[/bold blue]"):
                query_info = detect_query_type(query, llm)
                
            console.print(f"[dim]ğŸ” Detected: {query_info['type'].upper()} (Keywords: {query_info.get('keywords', [])})[/dim]")

            # ===================================================================
            # Step 2: ê²€ìƒ‰ ì „ëµ ì„ íƒ â­ ê°œì„ ë¨!
            # ===================================================================
            with console.status("[bold blue]ğŸ” Searching code...[/bold blue]"):
                
                # â­ íŠ¹ì • í•¨ìˆ˜ëª…ì´ ì–¸ê¸‰ëœ ê²½ìš° SmartSearchEngine ì‚¬ìš© (ì •í™• ë§¤ì¹­)
                if query_info.get('target_name'):
                    console.print(f"[cyan]ğŸ¯ Target function: {query_info['target_name']}[/cyan]")
                    if query_info.get('filename'):
                        console.print(f"[cyan]ğŸ“ In file: {query_info['filename']}[/cyan]")
                    
                    # ê°œì„ ëœ search ì—”ì§„ ì‚¬ìš© (ì •í™•í•œ í•¨ìˆ˜ëª… ë§¤ì¹­ ë¡œì§ í¬í•¨)
                    results = engine.search(query, top_k=10)
                
                # 1. ë‹¤ì¤‘ íŒŒì¼ ê²€ìƒ‰
                elif len(query_info['filenames']) > 1:
                    console.print(f"[cyan]ğŸ“ Multi-target: {', '.join(query_info['filenames'])}[/cyan]")
                    results = []
                    for fname in query_info['filenames']:
                        f_res = db.search_by_filepath(fname, top_k=20)
                        payloads = [r.payload if hasattr(r, 'payload') else r for r in f_res]
                        results.extend(payloads)

                # 2. ë‹¨ì¼ íŒŒì¼ ê²€ìƒ‰ (í•¨ìˆ˜ëª… ì—†ëŠ” ê²½ìš°ë§Œ)
                elif query_info['filename']:
                    console.print(f"[cyan]ğŸ“ Target file: {query_info['filename']}[/cyan]")
                    all_results = db.search_by_filepath(query_info['filename'], top_k=1000)
                    
                    if not all_results:
                        console.print("[red]âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.[/red]")
                        continue
                    
                    results = [r.payload if hasattr(r, 'payload') else r for r in all_results]
                    results = results[:50]
                    
                # 3. ì—ëŸ¬ íŠ¸ë ˆì´ìŠ¤ë°± ì²˜ë¦¬
                elif query_info['has_traceback']:
                    traceback_files = re.findall(r'File "([^"]+)"', query)
                    if traceback_files:
                        console.print(f"[cyan]ğŸš¨ Error in files: {', '.join(set(traceback_files))}[/cyan]")
                        results = []
                        for fname in set(traceback_files):
                            file_results = db.search_by_filepath(fname, top_k=50)
                            results.extend([r.payload if hasattr(r, 'payload') else r for r in file_results])
                    else:
                        results = engine.search(query, top_k=5)
                        
                # 4. ì¼ë°˜ Smart Search
                else:
                    search_query = " ".join(query_info.get('keywords', [])) if query_info.get('keywords') else query
                    if len(search_query) < 5: search_query = query
                    results = engine.search(search_query, top_k=5)
                
                # â­ Graph í™•ì¥ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                if results:
                    expanded_results = []
                    existing_names = set()
                    
                    for r in results:
                        if isinstance(r, dict) and 'chunk' in r:
                            existing_names.add(r['chunk'].get('qualified_name'))
                        elif isinstance(r, dict):
                            existing_names.add(r.get('qualified_name'))
                    
                    for r in results[:5]: 
                        current_qn = None
                        if isinstance(r, dict) and 'chunk' in r:
                            current_qn = r['chunk'].get('qualified_name')
                        
                        if current_qn:
                            callee_names = graph_store.get_callees(current_qn)
                            
                            for callee in callee_names:
                                if callee not in existing_names:
                                    callee_hits = db.search(callee, top_k=3)
                                    for hit in callee_hits:
                                        payload = hit.payload if hasattr(hit, 'payload') else hit
                                        hit_qn = payload.get('qualified_name') or payload.get('chunk', {}).get('qualified_name')
                                        
                                        if hit_qn == callee:
                                            expanded_results.append(payload)
                                            existing_names.add(callee)
                                            break

                    if expanded_results:
                        console.print(f"[dim cyan]ğŸ•¸ï¸ Graph Expanded: +{len(expanded_results)} related functions[/dim cyan]")
                        results.extend(expanded_results)

                if not results:
                    console.print("[red]âŒ ê´€ë ¨ ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.[/red]")
                    continue

            # ===================================================================
            # Step 3: ê²€ìƒ‰ ê²°ê³¼ ì‹œê°í™”
            # ===================================================================
            console.print()
            print_evidence_panel(results, query_info)

            # ===================================================================
            # Step 4: LLM ë¶„ì„
            # ===================================================================
            with console.status("[bold magenta]ğŸ§  Analyzing code...[/bold magenta]"):
                prompt = build_optimized_prompt(query, results, query_info)
                answer = llm.generate_response(prompt, query)

            # ===================================================================
            # Step 5: ë‹µë³€ ì¶œë ¥
            # ===================================================================
            console.print(Panel(
                Markdown(answer), 
                title=f"Answer [{query_info['type'].upper()}]",
                border_style="green"
            ))

            # ===================================================================
            # Step 6: ì°¸ì¡° íŒŒì¼ ëª©ë¡ ì¶œë ¥
            # ===================================================================
            referenced_files = set()
            for r in results:
                if isinstance(r, dict) and 'chunk' in r:
                    referenced_files.add(r['chunk']['filepath'])
                elif isinstance(r, dict) and 'filepath' in r:
                    referenced_files.add(r['filepath'])

            console.print(f"\n[dim]ğŸ“š Referenced Files ({len(referenced_files)}):[/dim]")
            for f in sorted(referenced_files):
                console.print(f"[dim]  â””â”€ {f}[/dim]")

    except KeyboardInterrupt:
        console.print("\n[yellow]Interrupted by user[/yellow]")
    
    finally:
        graph_store.close()
        console.print("\n[dim]ğŸ‘‹ Goodbye![/dim]")


if __name__ == "__main__":
    main()